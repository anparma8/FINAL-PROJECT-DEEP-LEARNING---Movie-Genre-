{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Genre Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGES Project Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes:\n",
    "Angela María Arias Rojas 201728551 - Raúl Andrés Pardo Moreno 201727367"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KAGGLE TEAM: RA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: Movie Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output: Probability of the movie belong to each genre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 1. Machine Learning Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# i. Reading Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, we upload the python modules and training and test text data from the available files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Personal path where the files are uploaded from.\n",
    "path='C:/AAndres/Maestria Analytics/Semestre Vacaciones/Deep Learning/1 Class/AppliedDeepLearningClass-master/finalProject'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining = pd.read_csv(os.path.join(path, 'data', 'dataTraining.csv'), encoding='UTF-8', index_col=0)\n",
    "dataTesting = pd.read_csv(os.path.join(path, 'data', 'dataTesting.csv'), encoding='UTF-8', index_col=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7895/7895 [01:53<00:00, 69.71it/s]\n"
     ]
    }
   ],
   "source": [
    "images_training = []\n",
    "for i in tqdm(dataTraining.index):\n",
    "    images_training.append(io.imread(os.path.join(path, 'images_resize_gray', str(i) + '_resize_gray.jpeg')).flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3383/3383 [00:42<00:00, 80.10it/s]\n"
     ]
    }
   ],
   "source": [
    "images_testing = []\n",
    "for i in tqdm(dataTesting.index):\n",
    "    images_testing.append(io.imread(os.path.join(path, 'images_resize_gray', str(i) + '_resize_gray.jpeg')).flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 40960), 7895)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_training = np.stack(images_training)\n",
    "images_training.shape, dataTraining.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3383, 40960), 3383)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_testing = np.stack(images_testing)\n",
    "images_testing.shape, dataTesting.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3107</th>\n",
       "      <td>2003</td>\n",
       "      <td>Most</td>\n",
       "      <td>most is the story of a single father who takes...</td>\n",
       "      <td>['Short', 'Drama']</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>2008</td>\n",
       "      <td>How to Be a Serial Killer</td>\n",
       "      <td>a serial killer decides to teach the secrets o...</td>\n",
       "      <td>['Comedy', 'Crime', 'Horror']</td>\n",
       "      <td>5.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6724</th>\n",
       "      <td>1941</td>\n",
       "      <td>A Woman's Face</td>\n",
       "      <td>in sweden ,  a female blackmailer with a disfi...</td>\n",
       "      <td>['Drama', 'Film-Noir', 'Thriller']</td>\n",
       "      <td>7.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4704</th>\n",
       "      <td>1954</td>\n",
       "      <td>Executive Suite</td>\n",
       "      <td>in a friday afternoon in new york ,  the presi...</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>1990</td>\n",
       "      <td>Narrow Margin</td>\n",
       "      <td>in los angeles ,  the editor of a publishing h...</td>\n",
       "      <td>['Action', 'Crime', 'Thriller']</td>\n",
       "      <td>6.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year                      title  \\\n",
       "3107  2003                       Most   \n",
       "900   2008  How to Be a Serial Killer   \n",
       "6724  1941             A Woman's Face   \n",
       "4704  1954            Executive Suite   \n",
       "2582  1990              Narrow Margin   \n",
       "\n",
       "                                                   plot  \\\n",
       "3107  most is the story of a single father who takes...   \n",
       "900   a serial killer decides to teach the secrets o...   \n",
       "6724  in sweden ,  a female blackmailer with a disfi...   \n",
       "4704  in a friday afternoon in new york ,  the presi...   \n",
       "2582  in los angeles ,  the editor of a publishing h...   \n",
       "\n",
       "                                  genres  rating  \n",
       "3107                  ['Short', 'Drama']     8.0  \n",
       "900        ['Comedy', 'Crime', 'Horror']     5.6  \n",
       "6724  ['Drama', 'Film-Noir', 'Thriller']     7.2  \n",
       "4704                           ['Drama']     7.4  \n",
       "2582     ['Action', 'Crime', 'Thriller']     6.6  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>title</th>\n",
       "      <th>plot</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999</td>\n",
       "      <td>Message in a Bottle</td>\n",
       "      <td>who meets by fate ,  shall be sealed by fate ....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1978</td>\n",
       "      <td>Midnight Express</td>\n",
       "      <td>the true story of billy hayes ,  an american c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1996</td>\n",
       "      <td>Primal Fear</td>\n",
       "      <td>martin vail left the chicago da ' s office to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1950</td>\n",
       "      <td>Crisis</td>\n",
       "      <td>husband and wife americans dr .  eugene and mr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1959</td>\n",
       "      <td>The Tingler</td>\n",
       "      <td>the coroner and scientist dr .  warren chapin ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year                title  \\\n",
       "1  1999  Message in a Bottle   \n",
       "4  1978     Midnight Express   \n",
       "5  1996          Primal Fear   \n",
       "6  1950               Crisis   \n",
       "7  1959          The Tingler   \n",
       "\n",
       "                                                plot  \n",
       "1  who meets by fate ,  shall be sealed by fate ....  \n",
       "4  the true story of billy hayes ,  an american c...  \n",
       "5  martin vail left the chicago da ' s office to ...  \n",
       "6  husband and wife americans dr .  eugene and mr...  \n",
       "7  the coroner and scientist dr .  warren chapin ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTesting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ii. Applying PCA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the objetive of evaluating various models and select the best of them, we reduce 'X' variable dimentionality in order to use it for running models in faster way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=32)\n",
    "images_training_pca = pca.fit_transform(images_training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_testing_pca = pca.transform(images_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 32), (3383, 32))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_training_pca.shape, images_testing_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iii. Setting up the variable 'Y'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7895, 24)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataTraining['genres'] = dataTraining['genres'].map(lambda x: eval(x))\n",
    "\n",
    "le = MultiLabelBinarizer()\n",
    "y_genres = le.fit_transform(dataTraining['genres'])\n",
    "y_genres.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) Random Forest Classifier Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we fit the Random Forest Classifier Algorithm to a sample of 4.000 images in order to see the performance of the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf=OneVsRestClassifier(RandomForestClassifier(n_jobs=-1, n_estimators=40, max_depth=4, random_state=88))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=4, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=40, n_jobs=-1,\n",
       "            oob_score=False, random_state=88, verbose=0, warm_start=False),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rf.fit(images_training[0:4000,:],y_genres[0:4000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rf = model_rf.predict_proba(images_training[4001:7000,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6101483032382503"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, roc_auc_score\n",
    "roc_auc_score(y_genres[4001:7000,], y_pred_rf,average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score of the model is just 0.61 but using just 4.000 images. The parameters of the model were changed in order to find the combination that provides the best sample accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Number of estimators was a sensitive parameter which provides a wide range of metrics on the sample. Finally, we found that nearly 40 parameters provided a the performance of the model. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit the model to the complet data and make predictions. The predictors to be used are the images without PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_rf.fit(images_training,y_genres)\n",
    "\n",
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_rf_img = model_rf.predict_proba(images_testing)\n",
    "\n",
    "pd.DataFrame(y_pred_rf_img, index=dataTesting.index, columns=cols).to_csv('pred_fr_img100.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model scored 0.5958 in kaggle, being our best model. For practical reasons, we run our model with gray images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PART 2. Deep Learning Algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# a) CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uploading modules to create the CNN model.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andres\\.anaconda\\navigator\\Anaconda_\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps before, we uploaded and shaped X variable for a Random Forest model. Now, we need to reshape this images to use them in our CNN model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "images_training_rsh=images_training.reshape(images_training.shape[0],256,160,1)\n",
    "images_testing_rsh=images_testing.reshape(images_testing.shape[0],256,160,1)\n",
    "images_training_rsh=images_training_rsh.astype('float32')\n",
    "images_testing_rsh=images_testing_rsh.astype('float32')\n",
    "images_training_rsh/=255\n",
    "images_testing_rsh/=255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7895, 256, 160, 1), (3383, 256, 160, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_training_rsh.shape, images_testing_rsh.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the CNN model: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andres\\.anaconda\\navigator\\Anaconda_\\lib\\site-packages\\ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\", input_shape=(256, 160,...)`\n",
      "  \n",
      "C:\\Users\\andres\\.anaconda\\navigator\\Anaconda_\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), activation=\"relu\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "model=Sequential()\n",
    "model.add(Convolution2D(32,3,3,activation='relu',input_shape=(256,160,1)))\n",
    "model.add(Convolution2D(32,3,3,activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dense(24,activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to find the best parameters for this model, we used a sample of 4.000 gray images (full size) and training it multiple  times changing parameters as activation, dropout and optimizers. \n",
    "\n",
    "According with those results, we noticed the best results of the model with relu activation, dropout less than 0.4 and with adam optimizer.\n",
    "\n",
    "Some of the combinations were quite similar in the sample training data used, so we selected one of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we fit the model with all images in gray using a batch size of 100 because we saw a peak in the accuracy around this number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(images_training_rsh,y_genres,batch_size=100,nb_epoch=5,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_img_cnn = model.predict_proba(images_testing_rsh)\n",
    "\n",
    "pd.DataFrame(y_pred_img_cnn, index=dataTesting.index, columns=cols).to_csv('pred_cnn_img102.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# b) Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For transfer learning, we have used the VGG16 Model. The 'imagenet' weigths are imported.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input\n",
    "from keras.models import Model\n",
    "from keras.applications.vgg16 import VGG16 \n",
    "model_vgg16 = VGG16(weights='imagenet', include_top=False)\n",
    "\n",
    "import keras.optimizers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get the best parameters combination, we tested multiple alternatives. Various activation layers and optimizers were included in previous models but the accuracy was quite similar and predictions were not good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andres\\.anaconda\\navigator\\Anaconda_\\lib\\site-packages\\ipykernel_launcher.py:10: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"ac...)`\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def deepTransferModel(input_size):\n",
    "    x_input = Input(input_size)\n",
    "    x = model_vgg16.get_layer(\"block5_pool\")(x_input)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(512)(x)\n",
    "    x = Activation(\"relu\")(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(24)(x)\n",
    "    x = Activation(\"sigmoid\")(x)\n",
    "    model1 = Model(inputs=x_input, output=x)\n",
    "    return model\n",
    "model1 = deepTransferModel(images_training_rsh.shape[1:])\n",
    "model1.compile(optimizer = keras.optimizers.RMSprop(lr=0.01, rho=0.9, epsilon=None, decay=0.0), loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7895/7895 [==============================] - ETA: 18:47 - loss: 8.6042 - acc: 0.0000e+ - ETA: 17:28 - loss: 14.7945 - acc: 0.0583   - ETA: 16:45 - loss: 15.7337 - acc: 0.044 - ETA: 16:30 - loss: 17.2779 - acc: 0.062 - ETA: 16:13 - loss: 17.8342 - acc: 0.056 - ETA: 16:01 - loss: 18.5434 - acc: 0.063 - ETA: 15:49 - loss: 18.7984 - acc: 0.059 - ETA: 15:42 - loss: 19.2507 - acc: 0.064 - ETA: 15:28 - loss: 19.4766 - acc: 0.061 - ETA: 15:18 - loss: 19.1767 - acc: 0.061 - ETA: 15:06 - loss: 19.1973 - acc: 0.063 - ETA: 14:58 - loss: 19.2617 - acc: 0.063 - ETA: 14:48 - loss: 19.3575 - acc: 0.066 - ETA: 14:38 - loss: 19.1646 - acc: 0.065 - ETA: 14:32 - loss: 19.0611 - acc: 0.063 - ETA: 14:22 - loss: 18.9668 - acc: 0.063 - ETA: 14:15 - loss: 18.7817 - acc: 0.064 - ETA: 14:05 - loss: 18.9074 - acc: 0.063 - ETA: 14:00 - loss: 18.9414 - acc: 0.064 - ETA: 13:50 - loss: 19.0241 - acc: 0.064 - ETA: 13:42 - loss: 19.1388 - acc: 0.063 - ETA: 13:33 - loss: 18.9907 - acc: 0.065 - ETA: 13:26 - loss: 19.2202 - acc: 0.065 - ETA: 13:20 - loss: 19.2290 - acc: 0.066 - ETA: 13:12 - loss: 19.3482 - acc: 0.068 - ETA: 13:03 - loss: 19.5041 - acc: 0.069 - ETA: 12:55 - loss: 19.5391 - acc: 0.069 - ETA: 12:47 - loss: 19.4575 - acc: 0.067 - ETA: 12:39 - loss: 19.4813 - acc: 0.068 - ETA: 12:32 - loss: 19.3862 - acc: 0.067 - ETA: 12:24 - loss: 19.4137 - acc: 0.068 - ETA: 12:17 - loss: 19.4049 - acc: 0.069 - ETA: 12:08 - loss: 19.4022 - acc: 0.068 - ETA: 12:00 - loss: 19.5040 - acc: 0.071 - ETA: 11:52 - loss: 19.5472 - acc: 0.071 - ETA: 11:43 - loss: 19.5001 - acc: 0.070 - ETA: 11:36 - loss: 19.4281 - acc: 0.070 - ETA: 11:27 - loss: 19.5201 - acc: 0.071 - ETA: 11:20 - loss: 19.5416 - acc: 0.070 - ETA: 11:12 - loss: 19.6164 - acc: 0.070 - ETA: 11:04 - loss: 19.6513 - acc: 0.071 - ETA: 10:57 - loss: 19.6944 - acc: 0.071 - ETA: 10:49 - loss: 19.6418 - acc: 0.071 - ETA: 10:42 - loss: 19.6425 - acc: 0.071 - ETA: 10:34 - loss: 19.6391 - acc: 0.071 - ETA: 10:26 - loss: 19.6314 - acc: 0.069 - ETA: 10:18 - loss: 19.6405 - acc: 0.070 - ETA: 10:11 - loss: 19.7065 - acc: 0.070 - ETA: 10:03 - loss: 19.6704 - acc: 0.070 - ETA: 9:55 - loss: 19.7027 - acc: 0.070 - ETA: 9:48 - loss: 19.6160 - acc: 0.07 - ETA: 9:40 - loss: 19.5706 - acc: 0.07 - ETA: 9:32 - loss: 19.5562 - acc: 0.06 - ETA: 9:25 - loss: 19.5683 - acc: 0.07 - ETA: 9:17 - loss: 19.6195 - acc: 0.07 - ETA: 9:09 - loss: 19.5576 - acc: 0.06 - ETA: 9:02 - loss: 19.5344 - acc: 0.07 - ETA: 8:55 - loss: 19.5337 - acc: 0.07 - ETA: 8:48 - loss: 19.4819 - acc: 0.07 - ETA: 8:40 - loss: 19.5089 - acc: 0.07 - ETA: 8:32 - loss: 19.4490 - acc: 0.07 - ETA: 8:25 - loss: 19.4478 - acc: 0.07 - ETA: 8:17 - loss: 19.5129 - acc: 0.07 - ETA: 8:10 - loss: 19.5443 - acc: 0.07 - ETA: 8:03 - loss: 19.5049 - acc: 0.07 - ETA: 7:55 - loss: 19.5332 - acc: 0.07 - ETA: 7:48 - loss: 19.5669 - acc: 0.07 - ETA: 7:40 - loss: 19.6123 - acc: 0.07 - ETA: 7:33 - loss: 19.6400 - acc: 0.07 - ETA: 7:25 - loss: 19.6418 - acc: 0.07 - ETA: 7:18 - loss: 19.6199 - acc: 0.07 - ETA: 7:11 - loss: 19.6529 - acc: 0.07 - ETA: 7:03 - loss: 19.6736 - acc: 0.07 - ETA: 6:56 - loss: 19.6260 - acc: 0.07 - ETA: 6:49 - loss: 19.6119 - acc: 0.07 - ETA: 6:41 - loss: 19.5938 - acc: 0.07 - ETA: 6:34 - loss: 19.5704 - acc: 0.07 - ETA: 6:27 - loss: 19.5977 - acc: 0.07 - ETA: 6:19 - loss: 19.5545 - acc: 0.07 - ETA: 6:12 - loss: 19.5574 - acc: 0.07 - ETA: 6:04 - loss: 19.5721 - acc: 0.07 - ETA: 5:57 - loss: 19.5635 - acc: 0.07 - ETA: 5:50 - loss: 19.5432 - acc: 0.07 - ETA: 5:42 - loss: 19.5277 - acc: 0.07 - ETA: 5:35 - loss: 19.5220 - acc: 0.07 - ETA: 5:28 - loss: 19.5095 - acc: 0.07 - ETA: 5:21 - loss: 19.5481 - acc: 0.07 - ETA: 5:14 - loss: 19.5539 - acc: 0.07 - ETA: 5:07 - loss: 19.5354 - acc: 0.07 - ETA: 4:59 - loss: 19.5386 - acc: 0.07 - ETA: 4:52 - loss: 19.5620 - acc: 0.07 - ETA: 4:45 - loss: 19.5496 - acc: 0.07 - ETA: 4:38 - loss: 19.5807 - acc: 0.07 - ETA: 4:31 - loss: 19.5420 - acc: 0.07 - ETA: 4:24 - loss: 19.5591 - acc: 0.07 - ETA: 4:16 - loss: 19.5332 - acc: 0.07 - ETA: 4:09 - loss: 19.5113 - acc: 0.07 - ETA: 4:02 - loss: 19.5284 - acc: 0.07 - ETA: 3:55 - loss: 19.5419 - acc: 0.07 - ETA: 3:48 - loss: 19.5253 - acc: 0.07 - ETA: 3:40 - loss: 19.5655 - acc: 0.07 - ETA: 3:33 - loss: 19.5642 - acc: 0.07 - ETA: 3:26 - loss: 19.5797 - acc: 0.07 - ETA: 3:19 - loss: 19.6259 - acc: 0.07 - ETA: 3:11 - loss: 19.6019 - acc: 0.07 - ETA: 3:04 - loss: 19.5916 - acc: 0.07 - ETA: 2:57 - loss: 19.5982 - acc: 0.07 - ETA: 2:50 - loss: 19.6605 - acc: 0.07 - ETA: 2:42 - loss: 19.6792 - acc: 0.07 - ETA: 2:35 - loss: 19.6816 - acc: 0.07 - ETA: 2:28 - loss: 19.6726 - acc: 0.07 - ETA: 2:21 - loss: 19.6844 - acc: 0.07 - ETA: 2:13 - loss: 19.6832 - acc: 0.07 - ETA: 2:06 - loss: 19.6820 - acc: 0.07 - ETA: 1:59 - loss: 19.6892 - acc: 0.07 - ETA: 1:52 - loss: 19.6695 - acc: 0.07 - ETA: 1:45 - loss: 19.6376 - acc: 0.07 - ETA: 1:37 - loss: 19.6283 - acc: 0.07 - ETA: 1:30 - loss: 19.6435 - acc: 0.07 - ETA: 1:23 - loss: 19.6395 - acc: 0.07 - ETA: 1:16 - loss: 19.6299 - acc: 0.07 - ETA: 1:08 - loss: 19.6627 - acc: 0.07 - ETA: 1:01 - loss: 19.6648 - acc: 0.07 - ETA: 54s - loss: 19.6540 - acc: 0.0751 - ETA: 47s - loss: 19.6792 - acc: 0.075 - ETA: 40s - loss: 19.6502 - acc: 0.074 - ETA: 32s - loss: 19.6572 - acc: 0.074 - ETA: 25s - loss: 19.6387 - acc: 0.074 - ETA: 18s - loss: 19.6540 - acc: 0.074 - ETA: 11s - loss: 19.6564 - acc: 0.074 - ETA: 4s - loss: 19.6731 - acc: 0.074 - 946s 120ms/step - loss: 19.6817 - acc: 0.0737\n",
      "Epoch 2/5\n",
      "7895/7895 [==============================] - ETA: 14:17 - loss: 20.3878 - acc: 0.050 - ETA: 14:21 - loss: 18.5522 - acc: 0.075 - ETA: 14:10 - loss: 18.4180 - acc: 0.072 - ETA: 14:09 - loss: 18.8955 - acc: 0.091 - ETA: 14:00 - loss: 18.8358 - acc: 0.093 - ETA: 13:52 - loss: 19.1542 - acc: 0.088 - ETA: 13:52 - loss: 19.1556 - acc: 0.092 - ETA: 13:44 - loss: 18.9067 - acc: 0.085 - ETA: 13:39 - loss: 18.8126 - acc: 0.087 - ETA: 13:31 - loss: 18.2627 - acc: 0.080 - ETA: 13:26 - loss: 18.4559 - acc: 0.077 - ETA: 13:22 - loss: 18.4801 - acc: 0.076 - ETA: 13:16 - loss: 18.4363 - acc: 0.074 - ETA: 13:11 - loss: 18.4307 - acc: 0.075 - ETA: 13:05 - loss: 18.3622 - acc: 0.078 - ETA: 13:01 - loss: 18.5205 - acc: 0.076 - ETA: 12:55 - loss: 18.6146 - acc: 0.072 - ETA: 12:49 - loss: 18.6384 - acc: 0.073 - ETA: 12:43 - loss: 18.5153 - acc: 0.073 - ETA: 12:36 - loss: 18.5627 - acc: 0.076 - ETA: 12:30 - loss: 18.5458 - acc: 0.078 - ETA: 12:23 - loss: 18.8059 - acc: 0.080 - ETA: 12:17 - loss: 18.8565 - acc: 0.079 - ETA: 12:11 - loss: 18.9912 - acc: 0.079 - ETA: 12:04 - loss: 19.0292 - acc: 0.078 - ETA: 11:57 - loss: 19.2215 - acc: 0.081 - ETA: 11:49 - loss: 19.2337 - acc: 0.082 - ETA: 11:42 - loss: 19.4594 - acc: 0.083 - ETA: 11:36 - loss: 19.4554 - acc: 0.085 - ETA: 11:30 - loss: 19.2934 - acc: 0.084 - ETA: 11:24 - loss: 19.2151 - acc: 0.084 - ETA: 11:17 - loss: 19.2228 - acc: 0.082 - ETA: 11:10 - loss: 19.2826 - acc: 0.082 - ETA: 11:03 - loss: 19.2001 - acc: 0.081 - ETA: 10:56 - loss: 19.3014 - acc: 0.081 - ETA: 10:49 - loss: 19.2992 - acc: 0.081 - ETA: 10:43 - loss: 19.3222 - acc: 0.082 - ETA: 10:36 - loss: 19.3762 - acc: 0.083 - ETA: 10:29 - loss: 19.4457 - acc: 0.083 - ETA: 10:23 - loss: 19.5730 - acc: 0.083 - ETA: 10:16 - loss: 19.5339 - acc: 0.082 - ETA: 10:10 - loss: 19.5649 - acc: 0.082 - ETA: 10:03 - loss: 19.5563 - acc: 0.081 - ETA: 9:58 - loss: 19.4978 - acc: 0.081 - ETA: 9:51 - loss: 19.5315 - acc: 0.08 - ETA: 9:45 - loss: 19.5482 - acc: 0.08 - ETA: 9:38 - loss: 19.5032 - acc: 0.08 - ETA: 9:31 - loss: 19.4451 - acc: 0.08 - ETA: 9:25 - loss: 19.4303 - acc: 0.08 - ETA: 9:18 - loss: 19.4082 - acc: 0.07 - ETA: 9:12 - loss: 19.4526 - acc: 0.07 - ETA: 9:04 - loss: 19.5033 - acc: 0.07 - ETA: 8:57 - loss: 19.5307 - acc: 0.07 - ETA: 8:50 - loss: 19.5289 - acc: 0.07 - ETA: 8:43 - loss: 19.4870 - acc: 0.07 - ETA: 8:36 - loss: 19.5366 - acc: 0.07 - ETA: 8:29 - loss: 19.5401 - acc: 0.07 - ETA: 8:22 - loss: 19.4327 - acc: 0.07 - ETA: 8:15 - loss: 19.4373 - acc: 0.07 - ETA: 8:08 - loss: 19.4143 - acc: 0.07 - ETA: 8:01 - loss: 19.3833 - acc: 0.07 - ETA: 7:54 - loss: 19.3278 - acc: 0.07 - ETA: 7:47 - loss: 19.3801 - acc: 0.07 - ETA: 7:40 - loss: 19.4225 - acc: 0.07 - ETA: 7:33 - loss: 19.5025 - acc: 0.07 - ETA: 7:26 - loss: 19.4739 - acc: 0.07 - ETA: 7:19 - loss: 19.4973 - acc: 0.07 - ETA: 7:12 - loss: 19.5280 - acc: 0.07 - ETA: 7:05 - loss: 19.5517 - acc: 0.07 - ETA: 6:58 - loss: 19.5312 - acc: 0.07 - ETA: 6:51 - loss: 19.5656 - acc: 0.07 - ETA: 6:44 - loss: 19.5393 - acc: 0.07 - ETA: 6:37 - loss: 19.5464 - acc: 0.07 - ETA: 6:30 - loss: 19.5614 - acc: 0.07 - ETA: 6:23 - loss: 19.5708 - acc: 0.07 - ETA: 6:17 - loss: 19.5592 - acc: 0.07 - ETA: 6:10 - loss: 19.5727 - acc: 0.07 - ETA: 6:03 - loss: 19.5494 - acc: 0.07 - ETA: 5:56 - loss: 19.5083 - acc: 0.07 - ETA: 5:50 - loss: 19.4786 - acc: 0.07 - ETA: 5:43 - loss: 19.4651 - acc: 0.07 - ETA: 5:36 - loss: 19.5117 - acc: 0.07 - ETA: 5:29 - loss: 19.5280 - acc: 0.07 - ETA: 5:23 - loss: 19.5642 - acc: 0.07 - ETA: 5:16 - loss: 19.5525 - acc: 0.07 - ETA: 5:09 - loss: 19.5688 - acc: 0.07 - ETA: 5:03 - loss: 19.5614 - acc: 0.07 - ETA: 4:56 - loss: 19.5596 - acc: 0.07 - ETA: 4:49 - loss: 19.5524 - acc: 0.07 - ETA: 4:42 - loss: 19.5932 - acc: 0.07 - ETA: 4:36 - loss: 19.6020 - acc: 0.07 - ETA: 4:29 - loss: 19.6079 - acc: 0.07 - ETA: 4:22 - loss: 19.6372 - acc: 0.07 - ETA: 4:15 - loss: 19.6296 - acc: 0.07 - ETA: 4:08 - loss: 19.6332 - acc: 0.07 - ETA: 4:01 - loss: 19.6507 - acc: 0.07 - ETA: 3:54 - loss: 19.6601 - acc: 0.07 - ETA: 3:48 - loss: 19.6843 - acc: 0.07 - ETA: 3:41 - loss: 19.6652 - acc: 0.07 - ETA: 3:34 - loss: 19.6954 - acc: 0.07 - ETA: 3:27 - loss: 19.6913 - acc: 0.07 - ETA: 3:20 - loss: 19.7022 - acc: 0.07 - ETA: 3:13 - loss: 19.7022 - acc: 0.07 - ETA: 3:07 - loss: 19.6939 - acc: 0.07 - ETA: 3:00 - loss: 19.6755 - acc: 0.07 - ETA: 2:53 - loss: 19.6667 - acc: 0.07 - ETA: 2:46 - loss: 19.6974 - acc: 0.07 - ETA: 2:39 - loss: 19.7157 - acc: 0.07 - ETA: 2:33 - loss: 19.7646 - acc: 0.07 - ETA: 2:26 - loss: 19.7638 - acc: 0.07 - ETA: 2:19 - loss: 19.7441 - acc: 0.07 - ETA: 2:12 - loss: 19.7301 - acc: 0.07 - ETA: 2:05 - loss: 19.7286 - acc: 0.07 - ETA: 1:59 - loss: 19.7137 - acc: 0.07 - ETA: 1:52 - loss: 19.6850 - acc: 0.07 - ETA: 1:45 - loss: 19.6707 - acc: 0.07 - ETA: 1:38 - loss: 19.6797 - acc: 0.07 - ETA: 1:31 - loss: 19.6801 - acc: 0.07 - ETA: 1:25 - loss: 19.6407 - acc: 0.07 - ETA: 1:18 - loss: 19.6424 - acc: 0.07 - ETA: 1:11 - loss: 19.6668 - acc: 0.07 - ETA: 1:04 - loss: 19.6654 - acc: 0.07 - ETA: 58s - loss: 19.6475 - acc: 0.0756 - ETA: 51s - loss: 19.6474 - acc: 0.075 - ETA: 44s - loss: 19.6624 - acc: 0.075 - ETA: 37s - loss: 19.6952 - acc: 0.075 - ETA: 30s - loss: 19.6910 - acc: 0.074 - ETA: 24s - loss: 19.7000 - acc: 0.074 - ETA: 17s - loss: 19.7099 - acc: 0.074 - ETA: 10s - loss: 19.7305 - acc: 0.074 - ETA: 3s - loss: 19.7269 - acc: 0.074 - 889s 113ms/step - loss: 19.7365 - acc: 0.0746\n",
      "Epoch 3/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7895/7895 [==============================] - ETA: 14:25 - loss: 21.5519 - acc: 0.083 - ETA: 14:15 - loss: 20.5521 - acc: 0.116 - ETA: 14:18 - loss: 19.8705 - acc: 0.127 - ETA: 14:07 - loss: 19.9327 - acc: 0.112 - ETA: 14:04 - loss: 19.2715 - acc: 0.100 - ETA: 13:55 - loss: 19.4178 - acc: 0.097 - ETA: 13:45 - loss: 19.7354 - acc: 0.090 - ETA: 13:43 - loss: 19.8730 - acc: 0.079 - ETA: 13:35 - loss: 19.9003 - acc: 0.077 - ETA: 13:30 - loss: 19.7312 - acc: 0.080 - ETA: 13:22 - loss: 19.5629 - acc: 0.075 - ETA: 13:15 - loss: 19.7287 - acc: 0.077 - ETA: 13:08 - loss: 19.7771 - acc: 0.075 - ETA: 13:00 - loss: 19.9508 - acc: 0.078 - ETA: 12:55 - loss: 20.0456 - acc: 0.084 - ETA: 12:47 - loss: 19.8301 - acc: 0.081 - ETA: 12:41 - loss: 19.8629 - acc: 0.079 - ETA: 12:34 - loss: 20.1027 - acc: 0.082 - ETA: 12:27 - loss: 20.0690 - acc: 0.081 - ETA: 12:21 - loss: 20.1550 - acc: 0.080 - ETA: 12:14 - loss: 20.0141 - acc: 0.078 - ETA: 12:08 - loss: 20.0175 - acc: 0.078 - ETA: 12:02 - loss: 20.1011 - acc: 0.076 - ETA: 11:55 - loss: 20.1963 - acc: 0.076 - ETA: 11:49 - loss: 20.1324 - acc: 0.077 - ETA: 11:42 - loss: 20.2237 - acc: 0.078 - ETA: 11:36 - loss: 20.0894 - acc: 0.078 - ETA: 11:29 - loss: 20.0180 - acc: 0.078 - ETA: 11:23 - loss: 19.9494 - acc: 0.079 - ETA: 11:16 - loss: 19.9471 - acc: 0.079 - ETA: 11:09 - loss: 19.8371 - acc: 0.079 - ETA: 11:03 - loss: 19.8124 - acc: 0.078 - ETA: 10:56 - loss: 19.7267 - acc: 0.077 - ETA: 10:49 - loss: 19.7365 - acc: 0.076 - ETA: 10:42 - loss: 19.7457 - acc: 0.076 - ETA: 10:36 - loss: 19.8548 - acc: 0.076 - ETA: 10:29 - loss: 19.9474 - acc: 0.076 - ETA: 10:22 - loss: 20.0368 - acc: 0.075 - ETA: 10:16 - loss: 19.9639 - acc: 0.073 - ETA: 10:09 - loss: 20.0148 - acc: 0.074 - ETA: 10:02 - loss: 19.9948 - acc: 0.072 - ETA: 9:55 - loss: 19.9750 - acc: 0.073 - ETA: 9:48 - loss: 19.9200 - acc: 0.07 - ETA: 9:42 - loss: 19.8316 - acc: 0.07 - ETA: 9:35 - loss: 19.7710 - acc: 0.07 - ETA: 9:29 - loss: 19.7040 - acc: 0.07 - ETA: 9:22 - loss: 19.6817 - acc: 0.07 - ETA: 9:15 - loss: 19.6896 - acc: 0.07 - ETA: 9:09 - loss: 19.7708 - acc: 0.07 - ETA: 9:02 - loss: 19.6912 - acc: 0.07 - ETA: 8:55 - loss: 19.7423 - acc: 0.07 - ETA: 8:49 - loss: 19.8024 - acc: 0.07 - ETA: 8:42 - loss: 19.8585 - acc: 0.07 - ETA: 8:36 - loss: 19.8302 - acc: 0.07 - ETA: 8:29 - loss: 19.8658 - acc: 0.07 - ETA: 8:22 - loss: 19.8938 - acc: 0.07 - ETA: 8:16 - loss: 19.8810 - acc: 0.07 - ETA: 8:09 - loss: 19.8846 - acc: 0.07 - ETA: 8:02 - loss: 19.8643 - acc: 0.07 - ETA: 7:56 - loss: 19.7894 - acc: 0.07 - ETA: 7:49 - loss: 19.8310 - acc: 0.07 - ETA: 7:43 - loss: 19.8184 - acc: 0.07 - ETA: 7:36 - loss: 19.7848 - acc: 0.07 - ETA: 7:29 - loss: 19.7709 - acc: 0.07 - ETA: 7:23 - loss: 19.7657 - acc: 0.07 - ETA: 7:16 - loss: 19.7371 - acc: 0.07 - ETA: 7:09 - loss: 19.7276 - acc: 0.07 - ETA: 7:03 - loss: 19.7110 - acc: 0.07 - ETA: 6:56 - loss: 19.6836 - acc: 0.07 - ETA: 6:50 - loss: 19.6971 - acc: 0.07 - ETA: 6:43 - loss: 19.6833 - acc: 0.07 - ETA: 6:36 - loss: 19.7225 - acc: 0.07 - ETA: 6:30 - loss: 19.6907 - acc: 0.07 - ETA: 6:23 - loss: 19.6751 - acc: 0.07 - ETA: 6:17 - loss: 19.6735 - acc: 0.07 - ETA: 6:10 - loss: 19.6507 - acc: 0.07 - ETA: 6:04 - loss: 19.6777 - acc: 0.06 - ETA: 5:57 - loss: 19.6979 - acc: 0.07 - ETA: 5:51 - loss: 19.6923 - acc: 0.07 - ETA: 5:44 - loss: 19.6461 - acc: 0.07 - ETA: 5:37 - loss: 19.6428 - acc: 0.07 - ETA: 5:30 - loss: 19.6857 - acc: 0.07 - ETA: 5:24 - loss: 19.6730 - acc: 0.07 - ETA: 5:17 - loss: 19.6662 - acc: 0.07 - ETA: 5:10 - loss: 19.6332 - acc: 0.07 - ETA: 5:04 - loss: 19.6698 - acc: 0.07 - ETA: 4:57 - loss: 19.6677 - acc: 0.07 - ETA: 4:50 - loss: 19.6763 - acc: 0.07 - ETA: 4:44 - loss: 19.6960 - acc: 0.07 - ETA: 4:37 - loss: 19.7080 - acc: 0.07 - ETA: 4:30 - loss: 19.7253 - acc: 0.07 - ETA: 4:24 - loss: 19.7448 - acc: 0.07 - ETA: 4:17 - loss: 19.7457 - acc: 0.07 - ETA: 4:10 - loss: 19.7471 - acc: 0.07 - ETA: 4:04 - loss: 19.7447 - acc: 0.07 - ETA: 3:57 - loss: 19.7256 - acc: 0.07 - ETA: 3:50 - loss: 19.7020 - acc: 0.07 - ETA: 3:44 - loss: 19.7062 - acc: 0.07 - ETA: 3:37 - loss: 19.7363 - acc: 0.07 - ETA: 3:30 - loss: 19.7166 - acc: 0.07 - ETA: 3:24 - loss: 19.7200 - acc: 0.07 - ETA: 3:17 - loss: 19.7107 - acc: 0.07 - ETA: 3:10 - loss: 19.6950 - acc: 0.07 - ETA: 3:04 - loss: 19.6965 - acc: 0.07 - ETA: 2:57 - loss: 19.7127 - acc: 0.07 - ETA: 2:50 - loss: 19.6895 - acc: 0.07 - ETA: 2:44 - loss: 19.6832 - acc: 0.07 - ETA: 2:37 - loss: 19.7066 - acc: 0.07 - ETA: 2:30 - loss: 19.7049 - acc: 0.07 - ETA: 2:24 - loss: 19.7204 - acc: 0.07 - ETA: 2:17 - loss: 19.6938 - acc: 0.07 - ETA: 2:10 - loss: 19.6955 - acc: 0.07 - ETA: 2:04 - loss: 19.6789 - acc: 0.07 - ETA: 1:57 - loss: 19.6838 - acc: 0.07 - ETA: 1:50 - loss: 19.6692 - acc: 0.07 - ETA: 1:44 - loss: 19.6676 - acc: 0.07 - ETA: 1:37 - loss: 19.6756 - acc: 0.07 - ETA: 1:30 - loss: 19.6730 - acc: 0.07 - ETA: 1:23 - loss: 19.6835 - acc: 0.07 - ETA: 1:17 - loss: 19.6680 - acc: 0.07 - ETA: 1:10 - loss: 19.6708 - acc: 0.07 - ETA: 1:03 - loss: 19.6759 - acc: 0.07 - ETA: 57s - loss: 19.6870 - acc: 0.0737 - ETA: 50s - loss: 19.6855 - acc: 0.074 - ETA: 43s - loss: 19.6992 - acc: 0.074 - ETA: 37s - loss: 19.7073 - acc: 0.074 - ETA: 30s - loss: 19.7072 - acc: 0.074 - ETA: 23s - loss: 19.7160 - acc: 0.075 - ETA: 17s - loss: 19.7578 - acc: 0.074 - ETA: 10s - loss: 19.7636 - acc: 0.074 - ETA: 3s - loss: 19.7474 - acc: 0.074 - 879s 111ms/step - loss: 19.7365 - acc: 0.0746\n",
      "Epoch 4/5\n",
      "7895/7895 [==============================] - ETA: 15:14 - loss: 20.5667 - acc: 0.050 - ETA: 14:47 - loss: 18.8505 - acc: 0.083 - ETA: 14:48 - loss: 19.0048 - acc: 0.066 - ETA: 14:36 - loss: 18.9178 - acc: 0.058 - ETA: 14:33 - loss: 18.8596 - acc: 0.053 - ETA: 14:31 - loss: 18.9352 - acc: 0.055 - ETA: 14:33 - loss: 18.6992 - acc: 0.057 - ETA: 14:23 - loss: 18.7238 - acc: 0.058 - ETA: 14:13 - loss: 19.0911 - acc: 0.064 - ETA: 14:15 - loss: 19.1372 - acc: 0.061 - ETA: 14:13 - loss: 19.2319 - acc: 0.063 - ETA: 14:14 - loss: 19.3158 - acc: 0.068 - ETA: 14:11 - loss: 19.4488 - acc: 0.067 - ETA: 14:02 - loss: 19.5862 - acc: 0.071 - ETA: 13:52 - loss: 19.4983 - acc: 0.067 - ETA: 13:46 - loss: 19.3319 - acc: 0.072 - ETA: 13:41 - loss: 19.1728 - acc: 0.072 - ETA: 13:36 - loss: 19.1425 - acc: 0.075 - ETA: 13:31 - loss: 19.4091 - acc: 0.076 - ETA: 13:23 - loss: 19.4969 - acc: 0.078 - ETA: 13:18 - loss: 19.4739 - acc: 0.080 - ETA: 13:12 - loss: 19.4870 - acc: 0.078 - ETA: 13:06 - loss: 19.4444 - acc: 0.079 - ETA: 12:57 - loss: 19.4713 - acc: 0.077 - ETA: 12:49 - loss: 19.4470 - acc: 0.076 - ETA: 12:39 - loss: 19.3799 - acc: 0.075 - ETA: 12:30 - loss: 19.3089 - acc: 0.074 - ETA: 12:22 - loss: 19.3400 - acc: 0.074 - ETA: 12:15 - loss: 19.3061 - acc: 0.074 - ETA: 12:09 - loss: 19.3999 - acc: 0.077 - ETA: 12:03 - loss: 19.3518 - acc: 0.075 - ETA: 11:57 - loss: 19.4196 - acc: 0.074 - ETA: 11:50 - loss: 19.3215 - acc: 0.074 - ETA: 11:44 - loss: 19.2958 - acc: 0.073 - ETA: 11:36 - loss: 19.3142 - acc: 0.072 - ETA: 11:30 - loss: 19.3564 - acc: 0.072 - ETA: 11:21 - loss: 19.3738 - acc: 0.072 - ETA: 11:14 - loss: 19.3667 - acc: 0.071 - ETA: 11:06 - loss: 19.4059 - acc: 0.071 - ETA: 10:58 - loss: 19.3566 - acc: 0.071 - ETA: 10:51 - loss: 19.3410 - acc: 0.071 - ETA: 10:43 - loss: 19.2771 - acc: 0.071 - ETA: 10:35 - loss: 19.2897 - acc: 0.072 - ETA: 10:28 - loss: 19.3282 - acc: 0.072 - ETA: 10:21 - loss: 19.3392 - acc: 0.072 - ETA: 10:12 - loss: 19.3659 - acc: 0.073 - ETA: 10:04 - loss: 19.2860 - acc: 0.073 - ETA: 9:57 - loss: 19.2810 - acc: 0.072 - ETA: 9:49 - loss: 19.2085 - acc: 0.07 - ETA: 9:42 - loss: 19.2620 - acc: 0.07 - ETA: 9:34 - loss: 19.2759 - acc: 0.07 - ETA: 9:27 - loss: 19.3357 - acc: 0.07 - ETA: 9:19 - loss: 19.3550 - acc: 0.07 - ETA: 9:12 - loss: 19.3432 - acc: 0.07 - ETA: 9:05 - loss: 19.3318 - acc: 0.07 - ETA: 8:59 - loss: 19.3565 - acc: 0.07 - ETA: 8:52 - loss: 19.3510 - acc: 0.07 - ETA: 8:44 - loss: 19.3581 - acc: 0.07 - ETA: 8:37 - loss: 19.3260 - acc: 0.07 - ETA: 8:30 - loss: 19.3561 - acc: 0.07 - ETA: 8:23 - loss: 19.4151 - acc: 0.07 - ETA: 8:16 - loss: 19.4048 - acc: 0.07 - ETA: 8:09 - loss: 19.4038 - acc: 0.07 - ETA: 8:01 - loss: 19.3600 - acc: 0.07 - ETA: 7:54 - loss: 19.3142 - acc: 0.07 - ETA: 7:47 - loss: 19.3816 - acc: 0.07 - ETA: 7:39 - loss: 19.4118 - acc: 0.07 - ETA: 7:32 - loss: 19.4169 - acc: 0.07 - ETA: 7:25 - loss: 19.4582 - acc: 0.07 - ETA: 7:18 - loss: 19.4233 - acc: 0.07 - ETA: 7:11 - loss: 19.4088 - acc: 0.07 - ETA: 7:03 - loss: 19.4149 - acc: 0.06 - ETA: 6:56 - loss: 19.4286 - acc: 0.07 - ETA: 6:49 - loss: 19.4573 - acc: 0.07 - ETA: 6:42 - loss: 19.4307 - acc: 0.07 - ETA: 6:34 - loss: 19.4626 - acc: 0.07 - ETA: 6:27 - loss: 19.5238 - acc: 0.07 - ETA: 6:20 - loss: 19.5219 - acc: 0.07 - ETA: 6:13 - loss: 19.5234 - acc: 0.07 - ETA: 6:06 - loss: 19.5364 - acc: 0.07 - ETA: 5:58 - loss: 19.5543 - acc: 0.07 - ETA: 5:51 - loss: 19.5718 - acc: 0.07 - ETA: 5:44 - loss: 19.5525 - acc: 0.07 - ETA: 5:38 - loss: 19.5663 - acc: 0.07 - ETA: 5:31 - loss: 19.6048 - acc: 0.07 - ETA: 5:23 - loss: 19.6056 - acc: 0.07 - ETA: 5:16 - loss: 19.6118 - acc: 0.07 - ETA: 5:09 - loss: 19.6203 - acc: 0.07 - ETA: 5:02 - loss: 19.6209 - acc: 0.07 - ETA: 4:55 - loss: 19.6019 - acc: 0.07 - ETA: 4:47 - loss: 19.6348 - acc: 0.07 - ETA: 4:40 - loss: 19.6397 - acc: 0.07 - ETA: 4:33 - loss: 19.6677 - acc: 0.07 - ETA: 4:26 - loss: 19.6267 - acc: 0.07 - ETA: 4:19 - loss: 19.6200 - acc: 0.07 - ETA: 4:12 - loss: 19.6084 - acc: 0.07 - ETA: 4:04 - loss: 19.6340 - acc: 0.07 - ETA: 3:57 - loss: 19.6252 - acc: 0.07 - ETA: 3:50 - loss: 19.6308 - acc: 0.07 - ETA: 3:43 - loss: 19.6390 - acc: 0.07 - ETA: 3:36 - loss: 19.6694 - acc: 0.07 - ETA: 3:28 - loss: 19.6422 - acc: 0.07 - ETA: 3:21 - loss: 19.6492 - acc: 0.07 - ETA: 3:14 - loss: 19.6572 - acc: 0.07 - ETA: 3:07 - loss: 19.6982 - acc: 0.07 - ETA: 3:00 - loss: 19.6932 - acc: 0.07 - ETA: 2:53 - loss: 19.6866 - acc: 0.07 - ETA: 2:46 - loss: 19.6701 - acc: 0.07 - ETA: 2:39 - loss: 19.6844 - acc: 0.07 - ETA: 2:32 - loss: 19.6984 - acc: 0.07 - ETA: 2:25 - loss: 19.6758 - acc: 0.07 - ETA: 2:18 - loss: 19.7179 - acc: 0.07 - ETA: 2:11 - loss: 19.7035 - acc: 0.07 - ETA: 2:03 - loss: 19.6843 - acc: 0.07 - ETA: 1:56 - loss: 19.6759 - acc: 0.07 - ETA: 1:49 - loss: 19.6970 - acc: 0.07 - ETA: 1:42 - loss: 19.7139 - acc: 0.07 - ETA: 1:35 - loss: 19.6988 - acc: 0.07 - ETA: 1:28 - loss: 19.6710 - acc: 0.07 - ETA: 1:21 - loss: 19.6795 - acc: 0.07 - ETA: 1:14 - loss: 19.6732 - acc: 0.07 - ETA: 1:07 - loss: 19.6940 - acc: 0.07 - ETA: 1:00 - loss: 19.7103 - acc: 0.07 - ETA: 53s - loss: 19.6915 - acc: 0.0746 - ETA: 46s - loss: 19.6854 - acc: 0.074 - ETA: 39s - loss: 19.6914 - acc: 0.074 - ETA: 32s - loss: 19.6983 - acc: 0.074 - ETA: 25s - loss: 19.7270 - acc: 0.074 - ETA: 18s - loss: 19.7090 - acc: 0.074 - ETA: 11s - loss: 19.6984 - acc: 0.074 - ETA: 4s - loss: 19.7250 - acc: 0.074 - 921s 117ms/step - loss: 19.7365 - acc: 0.0746\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7895/7895 [==============================] - ETA: 14:04 - loss: 19.6715 - acc: 0.116 - ETA: 14:10 - loss: 19.2983 - acc: 0.091 - ETA: 14:04 - loss: 19.1938 - acc: 0.077 - ETA: 14:03 - loss: 19.2909 - acc: 0.075 - ETA: 13:53 - loss: 18.9969 - acc: 0.083 - ETA: 13:45 - loss: 19.5819 - acc: 0.080 - ETA: 13:40 - loss: 19.5478 - acc: 0.078 - ETA: 13:32 - loss: 19.9252 - acc: 0.079 - ETA: 13:27 - loss: 19.6250 - acc: 0.083 - ETA: 13:19 - loss: 19.5550 - acc: 0.083 - ETA: 13:13 - loss: 19.5494 - acc: 0.077 - ETA: 13:09 - loss: 19.7088 - acc: 0.073 - ETA: 13:01 - loss: 19.7197 - acc: 0.080 - ETA: 12:56 - loss: 19.6075 - acc: 0.079 - ETA: 12:49 - loss: 19.6416 - acc: 0.080 - ETA: 12:43 - loss: 19.5670 - acc: 0.082 - ETA: 12:36 - loss: 19.3555 - acc: 0.083 - ETA: 12:30 - loss: 19.3730 - acc: 0.084 - ETA: 12:24 - loss: 19.3636 - acc: 0.082 - ETA: 12:17 - loss: 19.4820 - acc: 0.080 - ETA: 12:11 - loss: 19.6502 - acc: 0.085 - ETA: 12:04 - loss: 19.6552 - acc: 0.086 - ETA: 11:57 - loss: 19.6598 - acc: 0.086 - ETA: 11:50 - loss: 19.7287 - acc: 0.086 - ETA: 11:43 - loss: 19.8112 - acc: 0.086 - ETA: 11:37 - loss: 19.8185 - acc: 0.087 - ETA: 11:30 - loss: 19.7102 - acc: 0.086 - ETA: 11:24 - loss: 19.6960 - acc: 0.085 - ETA: 11:17 - loss: 19.6983 - acc: 0.085 - ETA: 11:10 - loss: 19.7491 - acc: 0.084 - ETA: 11:04 - loss: 19.6840 - acc: 0.083 - ETA: 10:57 - loss: 19.6995 - acc: 0.082 - ETA: 10:50 - loss: 19.7240 - acc: 0.081 - ETA: 10:44 - loss: 19.7066 - acc: 0.081 - ETA: 10:37 - loss: 19.7713 - acc: 0.082 - ETA: 10:31 - loss: 19.8232 - acc: 0.081 - ETA: 10:24 - loss: 19.9143 - acc: 0.081 - ETA: 10:18 - loss: 19.9299 - acc: 0.080 - ETA: 10:11 - loss: 19.9240 - acc: 0.079 - ETA: 10:05 - loss: 19.8804 - acc: 0.079 - ETA: 9:58 - loss: 19.8346 - acc: 0.079 - ETA: 9:51 - loss: 19.8691 - acc: 0.07 - ETA: 9:45 - loss: 19.8492 - acc: 0.07 - ETA: 9:38 - loss: 19.8275 - acc: 0.07 - ETA: 9:32 - loss: 19.8393 - acc: 0.07 - ETA: 9:25 - loss: 19.7792 - acc: 0.07 - ETA: 9:18 - loss: 19.7401 - acc: 0.07 - ETA: 9:12 - loss: 19.8220 - acc: 0.08 - ETA: 9:05 - loss: 19.8609 - acc: 0.08 - ETA: 8:58 - loss: 19.8130 - acc: 0.08 - ETA: 8:52 - loss: 19.7417 - acc: 0.08 - ETA: 8:45 - loss: 19.8041 - acc: 0.07 - ETA: 8:39 - loss: 19.7903 - acc: 0.07 - ETA: 8:32 - loss: 19.7450 - acc: 0.07 - ETA: 8:25 - loss: 19.7399 - acc: 0.07 - ETA: 8:19 - loss: 19.6822 - acc: 0.07 - ETA: 8:12 - loss: 19.6930 - acc: 0.07 - ETA: 8:05 - loss: 19.7389 - acc: 0.07 - ETA: 7:59 - loss: 19.6801 - acc: 0.07 - ETA: 7:52 - loss: 19.7123 - acc: 0.07 - ETA: 7:45 - loss: 19.7327 - acc: 0.07 - ETA: 7:39 - loss: 19.7221 - acc: 0.07 - ETA: 7:32 - loss: 19.7047 - acc: 0.07 - ETA: 7:26 - loss: 19.7242 - acc: 0.07 - ETA: 7:19 - loss: 19.7395 - acc: 0.07 - ETA: 7:13 - loss: 19.7063 - acc: 0.07 - ETA: 7:06 - loss: 19.6608 - acc: 0.07 - ETA: 6:59 - loss: 19.6741 - acc: 0.07 - ETA: 6:53 - loss: 19.6434 - acc: 0.07 - ETA: 6:46 - loss: 19.6532 - acc: 0.07 - ETA: 6:39 - loss: 19.7173 - acc: 0.07 - ETA: 6:33 - loss: 19.6881 - acc: 0.07 - ETA: 6:26 - loss: 19.6731 - acc: 0.07 - ETA: 6:20 - loss: 19.6788 - acc: 0.07 - ETA: 6:13 - loss: 19.7248 - acc: 0.07 - ETA: 6:06 - loss: 19.6959 - acc: 0.07 - ETA: 6:00 - loss: 19.7254 - acc: 0.07 - ETA: 5:53 - loss: 19.7113 - acc: 0.07 - ETA: 5:47 - loss: 19.6889 - acc: 0.07 - ETA: 5:40 - loss: 19.7047 - acc: 0.07 - ETA: 5:33 - loss: 19.6921 - acc: 0.07 - ETA: 5:27 - loss: 19.6857 - acc: 0.07 - ETA: 5:20 - loss: 19.6791 - acc: 0.07 - ETA: 5:14 - loss: 19.6516 - acc: 0.07 - ETA: 5:07 - loss: 19.6617 - acc: 0.07 - ETA: 5:00 - loss: 19.6694 - acc: 0.07 - ETA: 4:54 - loss: 19.6695 - acc: 0.07 - ETA: 4:47 - loss: 19.6579 - acc: 0.07 - ETA: 4:41 - loss: 19.6531 - acc: 0.07 - ETA: 4:34 - loss: 19.6519 - acc: 0.07 - ETA: 4:27 - loss: 19.6761 - acc: 0.07 - ETA: 4:21 - loss: 19.6806 - acc: 0.07 - ETA: 4:14 - loss: 19.6760 - acc: 0.07 - ETA: 4:08 - loss: 19.6794 - acc: 0.07 - ETA: 4:01 - loss: 19.6875 - acc: 0.07 - ETA: 3:54 - loss: 19.6830 - acc: 0.07 - ETA: 3:48 - loss: 19.6786 - acc: 0.07 - ETA: 3:41 - loss: 19.6505 - acc: 0.07 - ETA: 3:35 - loss: 19.6341 - acc: 0.07 - ETA: 3:28 - loss: 19.6437 - acc: 0.07 - ETA: 3:21 - loss: 19.6567 - acc: 0.07 - ETA: 3:15 - loss: 19.6575 - acc: 0.07 - ETA: 3:08 - loss: 19.6669 - acc: 0.07 - ETA: 3:02 - loss: 19.6514 - acc: 0.07 - ETA: 2:55 - loss: 19.6579 - acc: 0.07 - ETA: 2:48 - loss: 19.6831 - acc: 0.07 - ETA: 2:42 - loss: 19.7027 - acc: 0.07 - ETA: 2:35 - loss: 19.6552 - acc: 0.07 - ETA: 2:29 - loss: 19.6575 - acc: 0.07 - ETA: 2:22 - loss: 19.6278 - acc: 0.07 - ETA: 2:15 - loss: 19.6395 - acc: 0.07 - ETA: 2:09 - loss: 19.6491 - acc: 0.07 - ETA: 2:02 - loss: 19.6184 - acc: 0.07 - ETA: 1:56 - loss: 19.6343 - acc: 0.07 - ETA: 1:49 - loss: 19.6318 - acc: 0.07 - ETA: 1:43 - loss: 19.6131 - acc: 0.07 - ETA: 1:36 - loss: 19.6404 - acc: 0.07 - ETA: 1:29 - loss: 19.6541 - acc: 0.07 - ETA: 1:23 - loss: 19.6740 - acc: 0.07 - ETA: 1:16 - loss: 19.6862 - acc: 0.07 - ETA: 1:09 - loss: 19.6678 - acc: 0.07 - ETA: 1:03 - loss: 19.6561 - acc: 0.07 - ETA: 56s - loss: 19.6980 - acc: 0.0743 - ETA: 50s - loss: 19.7435 - acc: 0.074 - ETA: 43s - loss: 19.7484 - acc: 0.074 - ETA: 36s - loss: 19.7267 - acc: 0.074 - ETA: 30s - loss: 19.7133 - acc: 0.074 - ETA: 23s - loss: 19.7373 - acc: 0.074 - ETA: 17s - loss: 19.7363 - acc: 0.074 - ETA: 10s - loss: 19.7539 - acc: 0.074 - ETA: 3s - loss: 19.7444 - acc: 0.074 - 871s 110ms/step - loss: 19.7365 - acc: 0.0746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x241ebd58470>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1.fit(images_training_rsh, y_genres, epochs=5, verbose=1, batch_size=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['p_Action', 'p_Adventure', 'p_Animation', 'p_Biography', 'p_Comedy', 'p_Crime', 'p_Documentary', 'p_Drama', 'p_Family',\n",
    "        'p_Fantasy', 'p_Film-Noir', 'p_History', 'p_Horror', 'p_Music', 'p_Musical', 'p_Mystery', 'p_News', 'p_Romance',\n",
    "        'p_Sci-Fi', 'p_Short', 'p_Sport', 'p_Thriller', 'p_War', 'p_Western']\n",
    "\n",
    "y_pred_tl_img = model1.predict_proba(images_testing_rsh)\n",
    "\n",
    "pd.DataFrame(y_pred_tl_img, index=dataTesting.index, columns=cols).to_csv('pred_tl_img01.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transfer learning did not score well in kaggle. Possibly, the vgg16 weights have to been re-trained for this specific task in order to get better predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best model was Random Forest. The CNN models required a huge computational capacity so it was difficult to create more complex models. For that reason, we have just used the gray images, lossing information but trying to use various alternatives.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The disadvantage of working with images is the dimensionality. Unfortunately, when dimentions were reduced drastically, the predictions were not optimal  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
